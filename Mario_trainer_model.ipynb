{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "\n",
    "# Setup game\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v1')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "done = True\n",
    "for step in range(100000): \n",
    "    # Start the game to begin with \n",
    "    if done: \n",
    "        # Start the gamee\n",
    "        env.reset()\n",
    "    # Do random actions\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    # Show the game on the screen\n",
    "    env.render()\n",
    "# Close the game\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c57f1b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 89   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 22   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 23            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 174           |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0386488e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.00197      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 43.1          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -6.69e-05     |\n",
      "|    value_loss           | 159           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001703318 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.169        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 2.07         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000537    |\n",
      "|    value_loss           | 16           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 486          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007357751 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0806       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 0.321        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 15           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 642          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001573184 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.523        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000529    |\n",
      "|    value_loss           | 0.852        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 819          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008438026 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000668    |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 972          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005577266 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.137        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000842    |\n",
      "|    value_loss           | 0.75         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 14            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 1121          |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038692047 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | 0.159         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.14          |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.000533     |\n",
      "|    value_loss           | 0.588         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1267         |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005160079 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.127        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000805    |\n",
      "|    value_loss           | 0.783        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1415         |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033987612 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -5.84e-05    |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 14            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 1567          |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045494438 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.564         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 5.27          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000332     |\n",
      "|    value_loss           | 17.1          |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "\n",
    "# Base game\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v1')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 16, channels_order='last')\n",
    "\n",
    "import os \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "\n",
    "CHECKPOINT_DIR = './mario_model/'\n",
    "LOG_DIR = './logs/'\n",
    "# Setup model saving callback\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n",
    "# This is the AI model started\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001) \n",
    "# Train the AI model, this is where the AI model starts to learn\n",
    "model.learn(total_timesteps=1000000, callback=callback)\n",
    "model.save('marioppo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
